{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyMFeA5wywFz",
        "outputId": "550476dd-90af-4536-f726-66ce645a7bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ProductType Manufacturer Area Code Sourcing Channel Product Size  \\\n",
            "0        NTM3           X1       A28        WHOLESALE        Large   \n",
            "1        NTM2           X1        A9           DIRECT        Large   \n",
            "2        NTM3           X2       A20           DIRECT        Large   \n",
            "3        NTM3           X1       A18        WHOLESALE        Small   \n",
            "4        NTM2           X1       A28           DIRECT        Large   \n",
            "\n",
            "  Product Type Month of Sourcing  Sourcing Cost  \n",
            "0       Powder            May-21          10.16  \n",
            "1       Powder            Oct-20         134.28  \n",
            "2       Powder            Dec-20          12.46  \n",
            "3       Powder            Feb-21         107.22  \n",
            "4       Liquid            Nov-20         197.76  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 550176 entries, 0 to 550175\n",
            "Data columns (total 8 columns):\n",
            " #   Column             Non-Null Count   Dtype  \n",
            "---  ------             --------------   -----  \n",
            " 0   ProductType        550176 non-null  object \n",
            " 1   Manufacturer       550176 non-null  object \n",
            " 2   Area Code          550176 non-null  object \n",
            " 3   Sourcing Channel   550176 non-null  object \n",
            " 4   Product Size       550176 non-null  object \n",
            " 5   Product Type       550176 non-null  object \n",
            " 6   Month of Sourcing  550176 non-null  object \n",
            " 7   Sourcing Cost      550176 non-null  float64\n",
            "dtypes: float64(1), object(7)\n",
            "memory usage: 33.6+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the test dataset\n",
        "test_data = pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "# Display the first few rows and column information\n",
        "print(test_data.head())\n",
        "print(test_data.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Exploratory Data Analysis (EDA)\n"
      ],
      "metadata": {
        "id": "YjK-Wre5zDYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(test_data.isnull().sum())\n",
        "\n",
        "# Handle missing values (if any)\n",
        "# For example, fill missing values with mean or median\n",
        "test_data['Sourcing Cost'].fillna(test_data['Sourcing Cost'].median(), inplace=True)\n",
        "\n",
        "# Check for outliers\n",
        "# Visualize distributions or use statistical methods like Z-score or IQR to detect outliers\n",
        "# Decide on how to handle outliers (e.g., removal, transformation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5Dbr6oLzE0E",
        "outputId": "029466e8-6a75-4d7e-c4f7-ac8b1c220a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ProductType          0\n",
            "Manufacturer         0\n",
            "Area Code            0\n",
            "Sourcing Channel     0\n",
            "Product Size         0\n",
            "Product Type         0\n",
            "Month of Sourcing    0\n",
            "Sourcing Cost        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Feature Encoding"
      ],
      "metadata": {
        "id": "x39stDy9zLO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables using one-hot encoding\n",
        "test_data_encoded = pd.get_dummies(test_data, columns=['ProductType', 'Manufacturer', 'Area Code', 'Sourcing Channel', 'Product Size', 'Product Type'])\n",
        "\n",
        "# Display the updated DataFrame with encoded features\n",
        "print(test_data_encoded.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWiGPGDZzNsL",
        "outputId": "2cc2965e-91b8-4b7d-dd82-b5c3e61f3272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Month of Sourcing  Sourcing Cost  ProductType_NTM1  ProductType_NTM2  \\\n",
            "0            May-21          10.16             False             False   \n",
            "1            Oct-20         134.28             False              True   \n",
            "2            Dec-20          12.46             False             False   \n",
            "3            Feb-21         107.22             False             False   \n",
            "4            Nov-20         197.76             False              True   \n",
            "\n",
            "   ProductType_NTM3  Manufacturer_X1  Manufacturer_X2  Manufacturer_X3  \\\n",
            "0              True             True            False            False   \n",
            "1             False             True            False            False   \n",
            "2              True            False             True            False   \n",
            "3              True             True            False            False   \n",
            "4             False             True            False            False   \n",
            "\n",
            "   Area Code_A1  Area Code_A10  ...  Area Code_A9  Sourcing Channel_DIRECT  \\\n",
            "0         False          False  ...         False                    False   \n",
            "1         False          False  ...          True                     True   \n",
            "2         False          False  ...         False                     True   \n",
            "3         False          False  ...         False                    False   \n",
            "4         False          False  ...         False                     True   \n",
            "\n",
            "   Sourcing Channel_ECOM  Sourcing Channel_RETAIL  Sourcing Channel_WHOLESALE  \\\n",
            "0                  False                    False                        True   \n",
            "1                  False                    False                       False   \n",
            "2                  False                    False                       False   \n",
            "3                  False                    False                        True   \n",
            "4                  False                    False                       False   \n",
            "\n",
            "   Product Size_ExtraLarge  Product Size_Large  Product Size_Small  \\\n",
            "0                    False                True               False   \n",
            "1                    False                True               False   \n",
            "2                    False                True               False   \n",
            "3                    False               False                True   \n",
            "4                    False                True               False   \n",
            "\n",
            "   Product Type_Liquid  Product Type_Powder  \n",
            "0                False                 True  \n",
            "1                False                 True  \n",
            "2                False                 True  \n",
            "3                False                 True  \n",
            "4                 True                False  \n",
            "\n",
            "[5 rows x 62 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Train Different Machine Learning Models\n",
        "We'll train and evaluate the following models for predicting Sourcing Cost:\n",
        "\n",
        "Linear Regression\n",
        "Random Forest\n",
        "Gradient Boosting (e.g., XGBoost)\n",
        "We'll use these models to make predictions and compare their performance.\n",
        "\n",
        "1. Linear Regression"
      ],
      "metadata": {
        "id": "HVtMpqlrzOuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = test_data_encoded.drop(columns=['Month of Sourcing', 'Sourcing Cost'])\n",
        "y = test_data_encoded['Sourcing Cost']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Linear Regression model\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_linear = linear_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "rmse_linear = mean_squared_error(y_test, y_pred_linear, squared=False)\n",
        "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
        "\n",
        "print(\"Linear Regression Model:\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_linear}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_linear}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnOWP32I3g_3",
        "outputId": "d0d611de-47c4-4425-e72d-6a75a5320447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Model:\n",
            "Root Mean Squared Error (RMSE): 57.700506152593704\n",
            "Mean Absolute Error (MAE): 20.771198744047407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Gradient Boosting (XGBoost)"
      ],
      "metadata": {
        "id": "kDvQIDug3shB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "\n",
        "print(\"\\nXGBoost Model:\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_xgb}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_xgb}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gesex-bz3vHq",
        "outputId": "629d29d9-143d-4d90-855e-6bcffcd07122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "XGBoost Model:\n",
            "Root Mean Squared Error (RMSE): 56.09824154591503\n",
            "Mean Absolute Error (MAE): 16.25264462101416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# Assuming 'df' is your time series data with 'Month of Sourcing' and 'Sourcing Cost'\n",
        "# Convert 'Month of Sourcing' to datetime if necessary\n",
        "df['Month of Sourcing'] = pd.to_datetime(df['Month of Sourcing'])\n",
        "\n",
        "# Set 'Month of Sourcing' as the index\n",
        "df.set_index('Month of Sourcing', inplace=True)\n",
        "\n",
        "# Resample monthly and fill missing values if any\n",
        "df_monthly = df.resample('M').mean().fillna(method='ffill')\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_data = df_monthly.loc['2020-07-01':'2021-05-31', 'Sourcing Cost']\n",
        "test_data = df_monthly.loc['2021-06-01':, 'Sourcing Cost']\n",
        "\n",
        "# Fit ARIMA model\n",
        "model = ARIMA(train_data, order=(1, 1, 1))  # Example order, adjust as needed\n",
        "arima_model = model.fit()\n",
        "\n",
        "# Forecast\n",
        "forecast, stderr, conf_int = arima_model.forecast(len(test_data))\n",
        "\n",
        "# Evaluate the forecast\n",
        "rmse_arima = np.sqrt(np.mean((forecast - test_data)**2))\n",
        "mae_arima = np.mean(np.abs(forecast - test_data))\n",
        "\n",
        "print(\"\\nARIMA Model:\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_arima}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_arima}\")\n",
        "\n",
        "# Plot actual vs. forecasted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df_monthly.index, df_monthly['Sourcing Cost'], label='Actual')\n",
        "plt.plot(test_data.index, forecast, label='Forecast', linestyle='--')\n",
        "plt.title('ARIMA Forecasting')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sourcing Cost')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XoglZUJE6P0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.svm import SVR  # Import SVR class from sklearn.svm\n",
        "import xgboost as xgb\n"
      ],
      "metadata": {
        "id": "zhk2VKti5k0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the test dataset (assuming test_data_encoded is already prepared)\n",
        "# Replace this with your test dataset loading code if necessary\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = test_data_encoded.drop(columns=['Month of Sourcing', 'Sourcing Cost'])\n",
        "y = test_data_encoded['Sourcing Cost']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Linear Regression model\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with Linear Regression\n",
        "y_pred_linear = linear_reg.predict(X_test)\n",
        "\n",
        "# Evaluate Linear Regression model\n",
        "rmse_linear = mean_squared_error(y_test, y_pred_linear, squared=False)\n",
        "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with XGBoost\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate XGBoost model\n",
        "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "\n",
        "# Compare model performance\n",
        "models = ['Linear Regression', 'XGBoost']\n",
        "rmse_scores = [rmse_linear, rmse_xgb]\n",
        "mae_scores = [mae_linear, mae_xgb]\n",
        "\n",
        "model_comparison = pd.DataFrame({\n",
        "    'Model': models,\n",
        "    'RMSE': rmse_scores,\n",
        "    'MAE': mae_scores\n",
        "})\n",
        "\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(model_comparison)\n",
        "\n",
        "# Select the best model based on RMSE (lower is better)\n",
        "best_model_index = model_comparison['RMSE'].idxmin()\n",
        "best_model_name = model_comparison.loc[best_model_index, 'Model']\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEq6CpjP4soK",
        "outputId": "51d9d7b7-124c-40da-8518-53de7b611337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Comparison:\n",
            "               Model       RMSE        MAE\n",
            "0  Linear Regression  57.700506  20.771199\n",
            "1            XGBoost  56.098242  16.252645\n",
            "\n",
            "Best Model: XGBoost\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dr7wwruzz5j-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approaches for forecasting the June 2021 test set (Sourcing Cost) can vary depending on the characteristics of your dataset and the nature of the prediction task. Below are some common approaches you might consider:\n",
        "\n",
        "### Approaches for Forecasting:\n",
        "1. **Time Series Forecasting Techniques**:\n",
        "   - Use methods like ARIMA (AutoRegressive Integrated Moving Average) or SARIMA (Seasonal ARIMA) if the data exhibits time-dependent patterns and seasonality.\n",
        "   - Apply more advanced time series models like Prophet (from Facebook) or LSTM (Long Short-Term Memory) networks for capturing complex temporal dependencies.\n",
        "\n",
        "2. **Regression Models**:\n",
        "   - Utilize linear regression, polynomial regression, or regularized regression (e.g., Ridge, Lasso) if the relationship between features and target is primarily linear.\n",
        "   - Employ ensemble techniques like Random Forest or Gradient Boosting (e.g., XGBoost) for more robust performance and handling non-linear relationships.\n",
        "\n",
        "3. **Support Vector Machines (SVM)**:\n",
        "   - SVM can be effective for regression tasks, particularly when dealing with non-linear relationships between features and target variables.\n",
        "\n",
        "4. **Neural Networks**:\n",
        "   - Develop feedforward neural networks (e.g., Multi-layer Perceptron) or more complex architectures (e.g., deep neural networks) to capture intricate patterns in the data.\n",
        "\n",
        "5. **Ensemble Methods**:\n",
        "   - Combine predictions from multiple models (e.g., model averaging, stacking) to leverage diverse strengths and improve overall performance.\n",
        "\n",
        "### Comparison of Approaches:\n",
        "- **Time Series vs. Regression**:\n",
        "  - Time series models are suitable for data with inherent time dependencies and seasonality.\n",
        "  - Regression models can capture broader patterns and relationships but may overlook time-specific nuances.\n",
        "\n",
        "- **Linear Regression vs. Ensemble Models**:\n",
        "  - Linear regression is straightforward and interpretable but may underperform for complex data.\n",
        "  - Ensemble models like Random Forest and XGBoost are robust, handle non-linearity well, and often yield higher accuracy.\n",
        "\n",
        "- **SVM vs. Neural Networks**:\n",
        "  - SVM is effective for small to medium-sized datasets with non-linear relationships.\n",
        "  - Neural networks excel in capturing complex patterns but require more data and computational resources.\n",
        "\n",
        "### Final Approach and Justification:\n",
        "For this specific task of forecasting Sourcing Cost for June 2021, the chosen approach involves training and evaluating multiple regression-based models (e.g., Linear Regression, XGBoost) along with SVM for comparison. These models are well-suited for the task given the structured nature of the dataset and the focus on predicting a continuous target variable.\n",
        "\n",
        "- **Linear Regression**:\n",
        "  - Simple and interpretable, suitable for capturing linear relationships.\n",
        "\n",
        "- **XGBoost (Gradient Boosting)**:\n",
        "  - Robust ensemble method, capable of handling non-linear relationships and complex interactions.\n",
        "\n",
        "- **Support Vector Machine (SVM)**:\n",
        "  - Effective for capturing non-linear patterns and suitable for regression tasks.\n",
        "\n",
        "The final approach involves evaluating these models based on performance metrics (e.g., RMSE, MAE) and selecting the best-performing model for forecasting the June 2021 Sourcing Cost. This approach balances simplicity, accuracy, and model complexity, ensuring a thorough comparison to identify the most suitable model for the dataset and prediction task.\n",
        "\n",
        "In the notebook, detailed explanations will accompany each model's implementation, evaluation, and comparison, providing insights into their strengths, weaknesses, and suitability for the forecasting task based on empirical results and domain considerations."
      ],
      "metadata": {
        "id": "GA5zPTD7TSIH"
      }
    }
  ]
}